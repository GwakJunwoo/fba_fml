{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_PATH = \"https://github.com/GwakJunwoo/fba_fml/blob/master/datasets/housing/housing.csv\"\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(\"housing.csv\")\n",
    "\n",
    "housing = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "housing['income_cat'] = pd.cut(housing[\"median_income\"], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels = [1,2,3,4,5])\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in split.split(housing, housing['income_cat']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "\n",
    "for i in (strat_train_set, strat_test_set):\n",
    "    i.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns = housing_num.columns, index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "housing_cat = housing[['ocean_proximity']]\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): \n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = svm.SVR(kernel = 'linear')\n",
    "m2 = svm.SVR(kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111094.6308539982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pred = m1.predict(housing_prepared)\n",
    "m1_mse = mean_squared_error(housing_labels, pred)\n",
    "m1_rmse = np.sqrt(m1_mse)\n",
    "print(m1_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118580.68301157995\n"
     ]
    }
   ],
   "source": [
    "pred = m2.predict(housing_prepared)\n",
    "m2_mse = mean_squared_error(housing_labels, pred)\n",
    "m2_rmse = np.sqrt(m2_mse)\n",
    "print(m2_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for M1 is 111809.84009600841\n",
      "CV score for M2 is 118572.66762937943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores1 = cross_val_score(m1, housing_prepared, housing_labels, scoring= 'neg_mean_squared_error', cv=10)\n",
    "scores2 = cross_val_score(m2, housing_prepared, housing_labels, scoring= 'neg_mean_squared_error', cv=10)\n",
    "\n",
    "print(f'CV score for M1 is {np.sqrt(-scores1).mean()}')\n",
    "print(f'CV score for M2 is {np.sqrt(-scores2).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [0.5, 1.0, 2.0], 'gamma': ['scale', 'auto'],\n",
       "                          'kernel': ['linear']},\n",
       "                         {'C': [1.0, 5, 10.0, 20.0, 100.0],\n",
       "                          'gamma': ['scale', 'auto'], 'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'kernel':['linear'], 'C': [0.5, 1., 2.], 'gamma': ['scale', 'auto']},\n",
    "    {'kernel': ['rbf'], 'C': [1., 5, 10., 20., 100.], 'gamma': ['scale', 'auto']}]\n",
    "\n",
    "m = svm.SVR()\n",
    "grid_search = GridSearchCV(m, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100.0, gamma='auto')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115595.79530238075 {'C': 0.5, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "115595.79530238075 {'C': 0.5, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "112571.9845974018 {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "112571.9845974018 {'C': 1.0, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "107136.26398576611 {'C': 2.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "107136.26398576611 {'C': 2.0, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "118631.71004256308 {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "118634.4106689143 {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "117508.07539783238 {'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "117531.43159173557 {'C': 5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "116122.31346416594 {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "116146.756839778 {'C': 10.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "113501.46927897457 {'C': 20.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "113545.46943388201 {'C': 20.0, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "98079.63068270504 {'C': 100.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "97952.09207837719 {'C': 100.0, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for m, p in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-m), p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem2.\n",
    "\n",
    "$\\begin{aligned} {\\left[\\begin{array}{ll}x_{11} & x_{12} \\\\ x_{21} & x_{22}\\end{array}\\right]\\left[\\begin{array}{l}y_{1} \\\\ y_{2}\\end{array}\\right]+\\left[\\begin{array}{l}z_{1} \\\\ z_{2}\\end{array}\\right] } &=\\left[\\begin{array}{l}x_{11} y_{1}+x_{12} y_{2}+z_{1} \\\\ x_{21} y_{1}+x_{22} y_{2}+z_{2}\\end{array}\\right] \\\\ {\\left[\\begin{array}{l}y_{1} \\\\ y_{2}\\end{array}\\right]^{\\top}\\left[\\begin{array}{ll}x_{11} & x_{12} \\\\ x_{21} & x_{22}\\end{array}\\right]\\left[\\begin{array}{l}y_{1} \\\\ y_{2}\\end{array}\\right] } &=\\left[\\begin{array}{l}y_{1} x_{11}+y_{2} x_{21} \\\\ y_{1} x_{12}+y_{2} x_{22}\\end{array}\\right]^{\\top}\\left[\\begin{array}{l}y_{1} \\\\ y_{2}\\end{array}\\right] \\\\ &=y_{1}^{2} x_{11}+y_{1} y_{2} x_{21}+y_{1} x_{2} x_{12}+y_{2}^{2} x_{22} \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem3. \n",
    "\n",
    "(a) (n x d)(d x 1) = (n x 1)\n",
    "\n",
    "(b) {(d x n)(n x d)}<sup>-1</sup> = (d x d)\n",
    "\n",
    "(c) (d x d)(d x n)(n x 1) = (d x 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem4. \n",
    "\n",
    "(a) \n",
    "\n",
    "$\\begin{aligned} \\operatorname{Var}(a X+b) &=E\\left(a^{2} x^{2}+2 a b X+b^{2}\\right)-E(a x+b)^{2} \\\\ &\\left\\{a^{2} E\\left(x^{2}\\right)+2 a b E(x)+b^{2}\\right\\}-\\{a E(x)+b\\}^{2} \\\\ &=\\left\\{a^{2} E\\left(x^{2}\\right)+2 a b E(x)+b^{2}\\right\\}-\\left\\{a^{2} E(x)^{2}+a b E(x)+b^{2}\\right\\} \\\\ &=a^{2}\\left\\{E\\left(x^{2}\\right)-E(x)^{2}\\right\\} \\\\ &=a^{2} \\operatorname{Var}(X) \\end{aligned}$\n",
    "\n",
    "(b)\n",
    "\n",
    "$\\begin{aligned} \\bar{X} &=\\frac{1}{n} \\sum_{i=1}^{n} X_{2} \\\\ E(\\bar{X}) &=E\\left(\\frac{1}{n} \\sum_{i=1}^{n} x_{2}\\right)=\\frac{1}{n} E\\left(\\sum_{i=1}^{n} X_{2}\\right) \\\\ &=\\frac{1}{n} E\\left(X_{1}+x_{2}+\\cdots+x_{n}\\right)=\\frac{1}{n} \\cdot n \\cdot \\mu=\\mu \\\\ V(\\bar{x}) &=V\\left(\\frac{1}{n} \\sum_{i=1}^{n} x_{2}\\right)=\\left(\\frac{1}{n}\\right)^{2} V\\left(x_{1}+x_{2}+\\cdots+x_{n}\\right) \\\\ &=\\frac{1}{n^{2}} \\cdot n \\cdot \\sigma^{2}=\\frac{\\sigma^{2}}{n} \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem5.\n",
    "\n",
    "(a)\n",
    "\n",
    "$\\begin{aligned} P(y=1) &=\\sum_{k} P(y=1, x=k) \\\\ &=\\frac{10}{100}+\\frac{15}{100}=\\frac{1}{4}\\end{aligned}$\n",
    "\n",
    "(b)\n",
    "\n",
    "$\\begin{aligned} P(y=1 \\mid x=1)=\\frac{P(x=1, y=1)}{P(x=1)}=\\frac{\\frac{10}{100}}{\\frac{15}{100}}=\\frac{2}{3}\\end{aligned}$\n",
    "\n",
    "(c)\n",
    "\n",
    "$\\begin{aligned}P(x=1, y=1)=\\frac{10}{100} \\neq \\frac{15}{100} \\cdot \\frac{25}{100}=P(x=1) P(y=1) \\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) random variable X와 무관한 사건 Y=1이 발생할 확률\n",
    "\n",
    "(b) X=1이 발생했을 때, Y=1이 추가적으로 발생할 확률\n",
    "\n",
    "(c) X, Y는 독립이 아니다. 특정 사건이 발생했을 때, 그 사건의 발생이 다른 사건의 발생확률에 영향을 미치기 때문이다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "453c6a251d01d2b145c14d54216914f00870abc3639d0c85e21c1e8fecbc91a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
